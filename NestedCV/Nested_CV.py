# IMPORTS
import os
import sys
import shutil
import time
import signal
import pickle
import numpy as np

# Cross-validation and Grid Search
from sklearn.model_selection import KFold, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# Models
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis

# Custom models
from skelm import ELMClassifier
from CustomModels import EnsembleDeepRVFL, RVC, BroadNet, SCN, SupervisedOPF
from skrules import SkopeRules
from gplearn.genetic import SymbolicClassifier
from lightgbm.sklearn import LGBMClassifier
from catboost.catboost import CatBoostClassifier
from xgboost.sklearn import XGBClassifier

# Metrics
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score, precision_score, matthews_corrcoef, cohen_kappa_score

# Dataset
#import ember


# GLOBAL VARIABLES

# Paths
model_folder = './Models/'
result_folder = './Results/'
result_filename = './Results/Results.txt'


# Cross-Validation parameters
outer_splits = 5
inner_splits = 3
n_jobs = 8


# Model name list
model_names = [
        'K-Nearest Neighbors',
        'Support Vector Machine',
        'Decision Tree',
        'Random Forest',
        'Extreme Random Forest',
        'Gradient Boosted Machine',
        'MultiLayer Perceptron',
        'AdaBoost',
        'Gaussian Naive Bayes',
        'Extreme Learning Machine',
        'Ensemble Deep RVFL',
        'LightGBM',
        'Skope Rules',
        'GPLearn',
        'Relevance Vector Machine',
        'CatBoost',
        'XGBoost',
        'Broad Learning System',
        'Stochastic Configuration Network',
        'Logistic Regressor',
        'Linear Discriminant Analysis',
        'Quadratic Discriminant Analysis',
        'Optimus Path Forest']


# Model acronym list
model_acronyms = [
        'knn',
        'svc',
        'dt',
        'rf',
        'erf',
        'gbm',
        'mlp',
        'ab',
        'gnb',
        'elm',
        'edrvfl',
        'lgbm',
        'sr',
        'gpl',
        'rvm',
        'cb',
        'xgb',
        'bls',
        'scn',
        'lr',
        'lda',
        'qda',
        'opf']


# Model list
models = [
        KNeighborsClassifier(), 
        SVC(),
        DecisionTreeClassifier(), 
        RandomForestClassifier(), 
        ExtraTreesClassifier(),
        GradientBoostingClassifier(),
        MLPClassifier(),
        AdaBoostClassifier(),
        GaussianNB(),
        ELMClassifier(),
        EnsembleDeepRVFL(),
        LGBMClassifier(),
        SkopeRules(),
        SymbolicClassifier(),
        RVC(),
        CatBoostClassifier(),
        XGBClassifier(),
        BroadNet(),
        SCN(),
        LogisticRegression(),
        LinearDiscriminantAnalysis(),
        QuadraticDiscriminantAnalysis(),
        SupervisedOPF()]


# Models parameter grid
models_param_grid = [
    {
        # K-Nearest Neighbors
        'knn__n_neighbors' : [1, 3, 5, 7, 9],
        'knn__weights' : ["uniform", "distance"],
        'knn__p' : [1, 2, 3]
    },
    {
        # Support Vector Machine
        'svc__C' : [0.1, 1, 10, 100, 1000],
        'svc__gamma': [0.0001, 0.001, 0.01, 0.1, 1]
    },
    {
        # Decision tree
        'dt__criterion' : ["gini", "entropy"],
        'dt__splitter' : ["best", "random"],
        'dt__max_depth' : [None, 10, 20, 50]
    },
    {
        # Random Forest
        'rf__n_estimators' : [50, 100, 200],
        'rf__criterion' : ["gini", "entropy"],
        'rf__max_depth' : [None, 10, 20, 50]
    },
    {
        # Extreme Random Forest
        'erf__n_estimators' : [50, 100, 200],
        'erf__criterion' : ["gini", "entropy"],
        'erf__max_depth' : [None, 10, 20, 50]
    },
    {
        # Gradient Boosted Machine
        'gbm__loss' : ["deviance", 'exponential'],
        'gbm__learning_rate' : [0.01, 0.1, 1],
        'gbm__n_estimators' : [50, 100, 200], 
    },
    {
        # MultiLayer Perceptron
        'mlp__hidden_layer_sizes' : [(1000, 500, 200), (500, 200, 100), (200, 100, 50)],
        'mlp__activation' : ['identity', 'logistic', 'relu'],
        'mlp__alpha' : [0.00001, 0.0001, 0.001],
        'mlp__learning_rate_init' : [0.001, 0.01, 0.1]
    },
    {
        # Adaboost
        'ab__n_estimators' : [200, 500, 1000], 
        'ab__learning_rate' : [0.01, 0.1, 1]
    
    },
    {
        # Gaussian Naive Bayes
        'gnb__var_smoothing' : np.logspace(0, -9, 50)
    },
    {
        # Extreme Learning Machine
        'elm__n_neurons' : [200, 500, 1000],
        'elm__alpha' : [0.0001, 0.001, 0.01, 0.1],
    },
    {
        # Ensemble Deep RVFL
        'edrvfl__n_nodes' : [40, 80, 100, 200, 300],
        'edrvfl__n_layer' : [1, 2, 3, 4, 5],
        "edrvfl__activation" : ["relu", "sigmoid"]
    },
    {
        # LightGBM
        'lgbm__num_leaves' : [50, 500, 1000],
        'lgbm__max_depth' : [3, 6, 12]
    },
    {
        # Skope Rules
        'sr__max_depth_duplication' : [None, 2, 3],
        'sr__n_estimators' : [200, 500, 1000]
    },
    {
        # GPLearn
        'gpl__population_size' : [100, 1000, 10000],
        'gpl__generations' : [20, 50, 200],
        'gpl__tournament_size' : [20, 50, 200]
    },
    {
        # RVM
        'rvm__kernel' : ['linear', 'rbf'],
        'rvm__alpha' : [1e-6, 1e-5, 1e-4],
        'rvm__bias_used' : [False]
    },
    {
        # CatBoost
        'cb__l2_leaf_reg' : [1, 3, 5],
        'cb__learning_rate' : [0.001, 0.01, 0.1],
        'cb__depth' : [4, 6, 10],
        'cb__silent' : [True]
    },
    {
        # XGBoost
        'xgb__n_estimators' : [50, 100, 200],
        'xgb__max_depth' : [2, 4, 6],
        'xgb__eval_metric' : ['error'],
        'xgb__use_label_encoder' : [False]
    },
    {
        # BLS
        'bls__C' : [1e-04, 1e-03, 1e-02, 1e-01],
        'bls__N1' : [50, 100, 200, 500]
    },
    {
        # SCN
        'scn__L_max' : [10, 100, 1000],
        'scn__T_max' : [10, 100, 1000]
    },
        {
        # Logistic Regressor
        'lr__penalty' : ['l2', 'l1'],
        'lr__C' : [0.0001, 0.001, 0.1, 1],
        'lr__max_iter' : [10000],
        'lr__solver' : ['saga']
    },
    {
        # Linear Discriminant Analysis
        'lda__solver' : ['svd']
    },
    {
        # Quadractic Discriminant Analysis
        'qda__reg_param' : [0.001, 0.01, 0.1, 0]
    },
    {
        # OPF
        'opf__distance' : ['log_squared_euclidean', 'log_euclidean']
    }]


# UTILS

# Ctrl + C
def sigintHandler(sig, frame):
    
    print("\nSaliendo...\n")
    
    # Exit with error code
    sys.exit(1)
    
signal.signal(signal.SIGINT, sigintHandler)


# Bytes to various multiples
def bytesTo(bytes, to, bsize=1024): 
    
    # Mutiples acronyms
    a = {'k' : 1, 'm': 2, 'g' : 3, 't' : 4, 'p' : 5, 'e' : 6 }
    
    # Cast to float
    r = float(bytes)

    # Convert
    conversion = bytes / (bsize ** a[to]) 
    
    # Return conversion
    return conversion


# Check folders and files
def checkFolders():
    
    # Check if models folder exists, if not create it
    if not os.path.exists(model_folder):
        os.mkdir(model_folder)
    
    # Check if results folder exists, if not create it
    if not os.path.exists(result_folder):
        os.mkdir(result_folder)
    
    # Check if results file exist, if exists remove it
    if os.path.exists(result_filename):
        os.remove(result_filename)


# Clean ember vectors for cross-validation
def cleanVectors(X_train, y_train, X_test, y_test):
    
    # Reshape train vector
    X_train = np.reshape(X_train, (-1, 2381))

    # Search non labeled data
    unlabeled_index = np.argwhere(y_train==-1).flatten()
    
    # Delete non labeled data from X_train
    X_train = np.delete(X_train, unlabeled_index, 0)
    
    # Delete non labeled data from y_train
    y_train = np.delete(y_train, unlabeled_index, 0)

    # Join full dataset, both in X and y
    X = np.append(X_train, X_test, axis=0)
    y = np.append(y_train, y_test)

    # Shuffle dataset with random_state=0
    X_shuffled, y_shuffled = shuffle(X, y, random_state=0)

    # Return features vector and labels set as int (Avoid error in EDRVFL model)
    return X_shuffled, y_shuffled.astype(int)


# Load dataset
def loadDataset():
    
    # Try to load dataset
    try:
        X = np.load('../Dataset/ember2018/X_20k.npy')
        y = np.load('../Dataset/ember2018/y_20k.npy')
    
    # If either of them does not exit, print error and exit
    except OSError:
        print("El dataset no se encuentra en la ubicaci√≥n apropiada.\n")
        sys.exit(1)
    
    # Return dataset
    return X, y


# NESTED CV FUNCTIONS

# Create dictionary for each model
def createModelDict():
    
    # Model Score lists
    bacc = list()
    f1 = list()
    recall = list()
    precision = list()
    mcc = list()
    kappa = list()
    estimators = list()
    best_params = list()
    memory = list()
    fit_time = list()
    predict_time = list()
    fold_time = list()
    total_time = list()
    
    # Model Score dictionary
    model_nested_score = dict()
    model_nested_score['bacc'] = bacc
    model_nested_score['f1'] = f1
    model_nested_score['recall'] = recall
    model_nested_score['precision'] = precision
    model_nested_score['mcc'] = mcc
    model_nested_score['kappa'] = kappa
    model_nested_score['estimators'] = estimators
    model_nested_score['best_params'] = best_params
    model_nested_score['memory'] = memory
    model_nested_score['fit_time'] = fit_time
    model_nested_score['predict_time'] = predict_time
    model_nested_score['fold_time'] = fold_time
    model_nested_score['total_time'] = total_time
    
    #¬†Return model nested score dictionary
    return model_nested_score 


# Configure CV for each model
def configureCrossValidation(model, index):
    
    # Create each model dictionary
    model_nested_score = createModelDict()
    
    # Configure Outer CV Procedure
    cv_outer = KFold(n_splits=outer_splits,
                     shuffle=True,
                     random_state=1)

    # Configure Inner CV Procedure
    cv_inner = KFold(n_splits=inner_splits,
                     shuffle=True,
                     random_state=1)
    
    # Standar Scaler Pipeline for all the models
    estimator = Pipeline(steps=[('scaler', StandardScaler()),
                                (model_acronyms[index], model)])
    
    #¬†Return configured estimator, inner and outer CV and model nested score dictionary
    return estimator, cv_inner, cv_outer, model_nested_score


# Configure grid search, fit it and output result
def gridSearch(estimator, index, cv_inner, X_train, y_train):
    
    # Configure grid search
    gs = GridSearchCV(
            estimator=estimator,
            param_grid=models_param_grid[index],
            scoring='accuracy',
            cv=cv_inner,
            n_jobs=n_jobs,
            verbose=1)

    # Fit grid search
    result = gs.fit(X_train, y_train)
    
    # Return fitted grid search
    return result


# Measure models fit time
def fitTime(model_nested_score, best_model, X_train, y_train):
    
    # Models starting fit time
    fit_time_start = time.time()
    
    # Fit model
    best_model.fit(X_train, y_train)
    
    # Save models fit time
    model_nested_score['fit_time'].append(time.time() - fit_time_start)
    
    # Return models nested score dictionary and fitted model
    return model_nested_score, best_model
  
  
# Measure models predict time
def predictTime(model_nested_score, best_model, X_test):
    
    # Models starting predict time
    predict_time_start = time.time()
    
    # Predict model
    y_pred = best_model.predict(X_test)
    
    # Save models predict time
    model_nested_score['predict_time'].append(time.time() - predict_time_start)
    
    # Return models nested score dictionary, predicted model and predicted output
    return model_nested_score, best_model, y_pred


# Score models performance
def scorePerformance(model_nested_score, y_test, y_pred):
    
    # Measure balanced accuracy
    model_nested_score['bacc'].append(balanced_accuracy_score(y_test, y_pred))
    
    # Measure f1-score
    model_nested_score['f1'].append(f1_score(y_test, y_pred))
    
    # Measure recall
    model_nested_score['recall'].append(recall_score(y_test, y_pred))
    
    # Measure precision
    model_nested_score['precision'].append(precision_score(y_test, y_pred))
    
    # Measure mcc
    model_nested_score['mcc'].append(matthews_corrcoef(y_test, y_pred))
    
    # Measure kappa
    model_nested_score['kappa'].append(cohen_kappa_score(y_test, y_pred))
    
    # Return models nested score dictionary
    return model_nested_score


# Measure memory size of model
def memorySize(model_nested_score, index):
    
    # Iterate over all the estimators of a model
    for j, estimator in enumerate(model_nested_score['estimators'], start=1):  
        # Create filename for model to save
        models_filename = model_folder + model_acronyms[index] + str(j) + '.pkl'
        
        # Save model in a pickle
        with open(models_filename, 'wb') as file:
            pickle.dump(estimator[model_acronyms[index]], file)
        
        # Get memory size
        file_size = os.path.getsize(models_filename)
        
        # Add memory size to model nested score dictionary
        model_nested_score['memory'].append(file_size)
        
        # Delete model
        os.remove(models_filename)
    
    # Return models nested score dictionary
    return model_nested_score


# Score CV of a model
def scoreCrossValidation(model_nested_score, gs, X_train, y_train, X_test, y_test, index, fold_time):
    
    # Select best performing model
    best_model = gs.best_estimator_
    
    # Measure fit time
    model_nested_score, best_model = fitTime(model_nested_score=model_nested_score, 
                                             best_model=best_model, 
                                             X_train=X_train, 
                                             y_train=y_train)
                
    # Measure prediction time
    model_nested_score, best_model, y_pred = predictTime(model_nested_score=model_nested_score, 
                                                         best_model=best_model, 
                                                         X_test=X_test)
    
    # Score performance
    model_nested_score = scorePerformance(model_nested_score=model_nested_score, 
                                          y_test=y_test, 
                                          y_pred=y_pred)
    
    # Best estimator in each fold with its memory size
    model_nested_score = memorySize(model_nested_score=model_nested_score, 
                                    index=index)

    # Save best params
    model_nested_score['best_params'].append(gs.best_params_)
    
    # Save best estimator of the fold
    model_nested_score['estimators'].append(best_model)
        
    # Save fold time
    model_nested_score['fold_time'].append(time.time() - fold_time)
    
    # Return models nested score dictionary
    return model_nested_score


# CV procedure
def crossValidation(model, index, X, y):
    
    # Configure CV
    estimator, cv_inner, cv_outer, model_nested_score = configureCrossValidation(model=model, 
                                                                                 index=index)
    
    #¬†Split dataset for outer CV
    for train_ix, test_ix in cv_outer.split(X):
        
        # Fold starting time
        fold_time = time.time()
        
        # Split current dataset for outer CV
        X_train, X_test = X[train_ix, :], X[test_ix, :]
        y_train, y_test = y[train_ix], y[test_ix]
        
        # Make grid search (Inner CV)
        result = gridSearch(estimator=estimator, 
                            index=index, 
                            cv_inner=cv_inner, 
                            X_train=X_train, 
                            y_train=y_train)
        
        # Score CV
        model_nested_score = scoreCrossValidation(model_nested_score=model_nested_score, 
                                                  gs=result, 
                                                  X_train=X_train, 
                                                  y_train=y_train, 
                                                  X_test=X_test, 
                                                  y_test=y_test, 
                                                  index=index, 
                                                  fold_time=fold_time)
        
    # Return models nested score dictionary
    return model_nested_score


# Save readable log
def saveLog(model_nested_score, index, fullTime):
    
    # Open results filename in append mode
    with open(result_filename, 'a') as file:
        # Save models filename
        file.write('Model = %s\n' % (model_names[index]))
        
        # Save means of all performance scores
        file.write('BAcc = %.4f\n' % (np.array(model_nested_score['bacc']).mean()))
        file.write('F1 = %.4f\n' % (np.array(model_nested_score['f1']).mean()))
        file.write('Recall = %.4f\n' % (np.array(model_nested_score['recall']).mean()))
        file.write('Precision = %.4f\n' % (np.array(model_nested_score['precision']).mean()))
        file.write('Mcc = %.4f\n' % (np.array(model_nested_score['mcc']).mean()))
        file.write('Kappa = %.4f\n' % (np.array(model_nested_score['kappa']).mean()))
        
        # Save best estimators fit time, predict time and memory size
        file.write('Best estimator:\n')
        file.write('\tFit time = %.3fs (+/- %.3fs)\n' % (np.array(model_nested_score['fit_time']).mean(), np.array(model_nested_score['fit_time']).std()))
        file.write('\tPredict time = %.3fs (+/- %.3fs)\n' % (np.array(model_nested_score['predict_time']).mean(), np.array(model_nested_score['predict_time']).std()))
        file.write('\tMemory size = %.3f MB (+/- %.3f MB)\n' % (bytesTo(np.array(model_nested_score['memory']).mean(), 'm'), bytesTo(np.array(model_nested_score['memory']).std(), 'm')))
        
        # Save parameters of the best estimators
        file.write('Best estimator parameters:\n')
        for j, best_params in enumerate(model_nested_score['best_params'], start=1):
            file.write('\tEstimator %d = %s\n' % (j, str(best_params)))
        
        # Save time of each fold of the model
        file.write('Fit time:\n')
        for j, value in enumerate(model_nested_score['fold_time'], start=1):
            file.write('\tFold %d = %.3fs\n' % (j, value))
        
        # Save total time of the model
        file.write('Total Time = %.3fs\n' % (fullTime))
        file.write('\n')


# Save model results pickle
def saveModelPickle(model_nested_score, index):
    
    # Filename for each model
    model_filename = './Results/' + model_acronyms[index] + '.pkl'
    
    # Create model file and save model scores
    with open(model_filename, 'wb') as file:
        pickle.dump(model_nested_score, file)


# CV for a model
def modelCrossValidation(nested_score, model, index, X, y):
    
    # Model Nested CV starting time
    startModel = time.time()  
    
    # CV
    model_nested_score = crossValidation(model=model, 
                                         index=index, 
                                         X=X, 
                                         y=y)
        
    # Model Nested CV time
    fullModel = time.time() - startModel
    
    # Save model full time
    model_nested_score['total_time'].append(fullModel)
    
    # Save model results in nested_score dict
    nested_score[model_acronyms[index]] = model_nested_score
        
    # Save readable log 
    saveLog(model_nested_score=model_nested_score, 
            index=index, 
            fullTime=fullModel)        
    
    # Save model pickle
    saveModelPickle(model_nested_score=model_nested_score, 
                    index=index)
    
    # Print model finished
    print("%s finished. Elapsed %.3fs\n" % (model_names[index], fullModel))


# Save full time in the readable log (Cannot be made earlier)
def saveFullTime(fullTime):
    
    # Open results readable log and save full time
    with open(result_filename, 'a') as file:
        file.write('Full CV Time = %.3fs\n' % (fullTime))
        
        
# Add values to results dictionary
def saveResultsDict(resultsDict, nested_score, fullTime):
    
    # Add Nested Score dictionary to results dictionary
    resultsDict['nested_score'] = nested_score
    
    # Add Nested CV total time to results dictionary
    resultsDict['total_time'] = fullTime
    
    # Add model names to results dictionary
    resultsDict['model_names'] = model_names
    
    # Add models acronyms to results dictionary
    resultsDict['model_acronyms'] = model_acronyms
    
    # Add models parameter grid to results dictionary
    resultsDict['model_param_grid'] = models_param_grid
    
    # Return populated results dictionary
    return resultsDict


# Save results dictionary to a pickle
def saveResultsPickle(results):
    
    # Results pickle filename
    result_pickle_filename  = './Results/Results.pkl'

    # Create file and save results dictionary
    with open(result_pickle_filename, 'wb') as file:
        pickle.dump(results, file)


# Save all the results 
def saveFullResults(resultsDict, nested_score, fullTime):
    
    # Total time to results file
    saveFullTime(fullTime=fullTime)
    
    # Populate results pickle
    results = saveResultsDict(resultsDict=resultsDict, nested_score=nested_score, fullTime=fullTime)
    
    # Save results pickle
    saveResultsPickle(results=results)
    
    
# Nested Grid Search CV of all models 
def fullCrossValidation(X, y):
    
    # Create full results dictionary
    results = dict()
    
    # Create Nested Score dictionary
    nested_score = dict()
    
    # All models Nested CV starting time
    startFull = time.time()
    
    # Iterate over models
    for i, model in enumerate(models, start=0):   
        # Nested CV for each model
        modelCrossValidation(nested_score=nested_score, model=model, index=i, X=X, y=y)
    
    # All models Nested CV time
    fullTime = time.time() - startFull

    # Save full results
    saveFullResults(resultsDict=results, nested_score=nested_score, fullTime=fullTime)
    
    # Clean
    os.rmdir(model_folder)

   
# MAIN
if __name__ == '__main__':
    
    # Check folders
    checkFolders()
   
    # Load dataset
    X, y = loadDataset()
        
    # Nested Grid Search Cross Validation of all models
    fullCrossValidation(X=X, y=y)